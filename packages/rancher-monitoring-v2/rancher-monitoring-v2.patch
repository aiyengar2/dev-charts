diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/Chart.yaml packages/rancher-monitoring-v2/charts/Chart.yaml
--- packages/rancher-monitoring-v2/charts-original/Chart.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/Chart.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -13,7 +13,7 @@
 - name: bismarck
 - email: gianrubio@gmail.com
   name: gianrubio
-name: prometheus-operator
+name: rancher-monitoring-v2
 sources:
 - https://github.com/coreos/kube-prometheus
 - https://github.com/coreos/prometheus-operator
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/README.md packages/rancher-monitoring-v2/charts/README.md
--- packages/rancher-monitoring-v2/charts-original/README.md	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/README.md	2020-07-19 20:14:04.000000000 -0700
@@ -291,6 +291,7 @@
 | `prometheus.prometheusSpec.evaluationInterval` | Interval between consecutive evaluations. | `""` |
 | `prometheus.prometheusSpec.externalLabels` | The labels to add to any time series or alerts when communicating with external systems (federation, remote storage, Alertmanager). | `{}` |
 | `prometheus.prometheusSpec.externalUrl` | The external URL the Prometheus instances will be available under. This is necessary to generate correct URLs. This is necessary if Prometheus is not served from root of a DNS name. | `""` |
+| `prometheus.prometheusSpec.ignoreNamespaceSelectors` | Ignore NamespaceSelector settings from the PodMonitor and ServiceMonitor configs. If true, PodMonitors and ServiceMonitors can only discover Pods and Services within the namespace they are deployed into | `false` |
 | `prometheus.prometheusSpec.image.repository` | Base image to use for a Prometheus deployment. | `quay.io/prometheus/prometheus` |
 | `prometheus.prometheusSpec.image.tag` | Tag of Prometheus container image to be deployed. | `v2.18.1` |
 | `prometheus.prometheusSpec.listenLocal` | ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP. | `false` |
@@ -465,6 +466,10 @@
 | `grafana.namespaceOverride` | Override the deployment namespace of grafana | `""` (`Release.Namespace`) |
 | `grafana.rbac.pspUseAppArmor` | Enforce AppArmor in created PodSecurityPolicy (requires rbac.pspEnabled) | `true` |
 | `grafana.service.portName` | Allow to customize Grafana service portname. Will be used by servicemonitor as well | `service` |
+| `grafana.service.port` | Kubernetes port where Grafana is exposed | `80` |
+| `grafana.service.targetPort` | Internal service port for Grafana | `3000` |
+| `grafana.service.nodePort` | Port to expose on each node running Grafana | `30950` |
+| `grafana.service.type` | Type of Kubernetes Service used for Grafana | `NodePort` |
 | `grafana.serviceMonitor.metricRelabelings` | The `metric_relabel_configs` for scraping the grafana instance. | `` |
 | `grafana.serviceMonitor.relabelings` | The `relabel_configs` for scraping the grafana instance. | `` |
 | `grafana.serviceMonitor.selfMonitor` | Create a `serviceMonitor` to automatically monitor the grafana instance | `true` |
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/requirements.yaml packages/rancher-monitoring-v2/charts/requirements.yaml
--- packages/rancher-monitoring-v2/charts-original/requirements.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/requirements.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -14,3 +14,8 @@
     version: "5.3.*"
     repository: https://kubernetes-charts.storage.googleapis.com/
     condition: grafana.enabled
+
+  - name: prometheus-adapter
+    version: 2.4.*
+    repository: https://kubernetes-charts.storage.googleapis.com/
+    condition: prometheus-adapter.enabled
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/exporters/core-dns/servicemonitor.yaml packages/rancher-monitoring-v2/charts/templates/exporters/core-dns/servicemonitor.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/exporters/core-dns/servicemonitor.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/exporters/core-dns/servicemonitor.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -3,7 +3,7 @@
 kind: ServiceMonitor
 metadata:
   name: {{ template "prometheus-operator.fullname" . }}-coredns
-  namespace: {{ template "prometheus-operator.namespace" . }}
+  namespace: "kube-system"
   labels:
     app: {{ template "prometheus-operator.name" . }}-coredns
 {{ include "prometheus-operator.labels" . | indent 4 }}
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/exporters/kube-api-server/servicemonitor.yaml packages/rancher-monitoring-v2/charts/templates/exporters/kube-api-server/servicemonitor.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/exporters/kube-api-server/servicemonitor.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/exporters/kube-api-server/servicemonitor.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -3,7 +3,7 @@
 kind: ServiceMonitor
 metadata:
   name: {{ template "prometheus-operator.fullname" . }}-apiserver
-  namespace: {{ template "prometheus-operator.namespace" . }}
+  namespace: default
   labels:
     app: {{ template "prometheus-operator.name" . }}-apiserver
 {{ include "prometheus-operator.labels" . | indent 4 }}
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/exporters/kube-controller-manager/servicemonitor.yaml packages/rancher-monitoring-v2/charts/templates/exporters/kube-controller-manager/servicemonitor.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/exporters/kube-controller-manager/servicemonitor.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/exporters/kube-controller-manager/servicemonitor.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -3,7 +3,7 @@
 kind: ServiceMonitor
 metadata:
   name: {{ template "prometheus-operator.fullname" . }}-kube-controller-manager
-  namespace: {{ template "prometheus-operator.namespace" . }}
+  namespace: "kube-system"
   labels:
     app: {{ template "prometheus-operator.name" . }}-kube-controller-manager
 {{ include "prometheus-operator.labels" . | indent 4 }}
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/exporters/kubelet/servicemonitor.yaml packages/rancher-monitoring-v2/charts/templates/exporters/kubelet/servicemonitor.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/exporters/kubelet/servicemonitor.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/exporters/kubelet/servicemonitor.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -3,7 +3,7 @@
 kind: ServiceMonitor
 metadata:
   name: {{ template "prometheus-operator.fullname" . }}-kubelet
-  namespace: {{ template "prometheus-operator.namespace" . }}
+  namespace: {{ .Values.kubelet.namespace }}
   labels:
     app: {{ template "prometheus-operator.name" . }}-kubelet
 {{- include "prometheus-operator.labels" . | indent 4 }}
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/prometheus/prometheus.yaml packages/rancher-monitoring-v2/charts/templates/prometheus/prometheus.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/prometheus/prometheus.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/prometheus/prometheus.yaml	2020-07-19 20:14:04.000000000 -0700
@@ -56,6 +56,9 @@
 {{- else }}
   externalUrl: http://{{ template "prometheus-operator.fullname" . }}-prometheus.{{ template "prometheus-operator.namespace" . }}:{{ .Values.prometheus.service.port }}
 {{- end }}
+{{- if .Values.prometheus.prometheusSpec.ignoreNamespaceSelectors }}
+  ignoreNamespaceSelectors: {{ .Values.prometheus.prometheusSpec.ignoreNamespaceSelectors }}
+{{- end }}
 {{- if .Values.prometheus.prometheusSpec.nodeSelector }}
   nodeSelector:
 {{ toYaml .Values.prometheus.prometheusSpec.nodeSelector | indent 4 }}
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/rancher-monitoring-v2/grafana-configmap-roles.yaml packages/rancher-monitoring-v2/charts/templates/rancher-monitoring-v2/grafana-configmap-roles.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/rancher-monitoring-v2/grafana-configmap-roles.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/rancher-monitoring-v2/grafana-configmap-roles.yaml	2020-07-19 20:47:34.000000000 -0700
@@ -0,0 +1,22 @@
+{{- if .Values.monitoringRoles }}
+{{- if and .Values.monitoringRoles.create .Values.grafana.enabled }}
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: grafana-config-edit
+  labels: {{ include "prometheus-operator.labels" . | nindent 4 }}
+rules:
+- apiGroups: [""] # "" indicates the core API group
+  resources: ["configmaps", "secrets"]
+  verbs: ["*"]
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: grafana-config-view
+  labels: {{ include "prometheus-operator.labels" . | nindent 4 }}
+rules:
+- apiGroups: [""] # "" indicates the core API group
+  resources: ["configmaps", "secrets"]
+  verbs: ["get", "watch", "list"]
+{{- end }}{{- end }}
\ No newline at end of file
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/templates/rancher-monitoring-v2/monitoring-roles.yaml packages/rancher-monitoring-v2/charts/templates/rancher-monitoring-v2/monitoring-roles.yaml
--- packages/rancher-monitoring-v2/charts-original/templates/rancher-monitoring-v2/monitoring-roles.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/templates/rancher-monitoring-v2/monitoring-roles.yaml	2020-07-19 20:18:23.000000000 -0700
@@ -0,0 +1,85 @@
+{{- if .Values.monitoringRoles }}{{- if .Values.monitoringRoles.create }}
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: monitoring-admin
+  labels: {{ include "prometheus-operator.labels" . | nindent 4 }}
+  {{- if .Values.monitoringRoles.aggregateRolesForRBAC }}
+    rbac.authorization.k8s.io/aggregate-to-admin: "true"
+  {{- end }}
+rules:
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheuses"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["alertmanagers"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["servicemonitors"]
+  verbs: ["*"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["podmonitors"]
+  verbs: ["*"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheusrules"]
+  verbs: ["*"]
+- apiGroups: [""] # "" indicates the core API group
+  resources: ["configmaps", "secrets"]
+  verbs: ["*"]
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: monitoring-edit
+  labels: {{ include "prometheus-operator.labels" . | nindent 4 }}
+  {{- if .Values.monitoringRoles.aggregateRolesForRBAC }}
+    rbac.authorization.k8s.io/aggregate-to-edit: "true"
+  {{- end }}
+rules:
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheuses"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["alertmanagers"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["servicemonitors"]
+  verbs: ["*"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["podmonitors"]
+  verbs: ["*"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheusrules"]
+  verbs: ["*"]
+- apiGroups: [""] # "" indicates the core API group
+  resources: ["configmaps", "secrets"]
+  verbs: ["*"]
+---
+apiVersion: rbac.authorization.k8s.io/v1
+kind: ClusterRole
+metadata:
+  name: monitoring-view
+  labels: {{ include "prometheus-operator.labels" . | nindent 4 }}
+  {{- if .Values.monitoringRoles.aggregateRolesForRBAC }}
+    rbac.authorization.k8s.io/aggregate-to-view: "true"
+  {{- end }}
+rules:
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheuses"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["alertmanagers"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["servicemonitors"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["podmonitors"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: ["monitoring.coreos.com"] # "" indicates the core API group
+  resources: ["prometheusrules"]
+  verbs: ["get", "watch", "list"]
+- apiGroups: [""] # "" indicates the core API group
+  resources: ["configmaps", "secrets"]
+  verbs: ["get", "watch", "list"]
+{{- end }}{{- end }}
\ No newline at end of file
diff -x '*.tgz' -x '*.lock' -uNr packages/rancher-monitoring-v2/charts-original/values.yaml packages/rancher-monitoring-v2/charts/values.yaml
--- packages/rancher-monitoring-v2/charts-original/values.yaml	1969-12-31 16:00:00.000000000 -0800
+++ packages/rancher-monitoring-v2/charts/values.yaml	2020-07-19 20:17:54.000000000 -0700
@@ -2,13 +2,35 @@
 # This is a YAML-formatted file.
 # Declare variables to be passed into your templates.
 
+# Rancher Monitoring V2 Configuration
+
+## Deploy some default ClusterRoles to allow users to interact with Prometheus CRs, ConfigMaps, and Secrets
+##
+monitoringRoles:
+  create: true
+  aggregateRolesForRBAC: false
+
+## Configuration for prometheus-adapter
+## ref: https://github.com/helm/charts/tree/master/stable/prometheus-adapter
+##
+prometheus-adapter:
+  enabled: true
+  prometheus:
+    # Change this if you change the namespaceOverride or nameOverride of prometheus-operator
+    url: http://rancher-monitoring-v2-prometheus.rancher-monitoring-v2.svc
+    port: 9090
+
+# Prometheus Operator Configuration
+
 ## Provide a name in place of prometheus-operator for `app:` labels
+## NOTE: If you change this value, you must update the prometheus-adapter.prometheus.url
 ##
-nameOverride: ""
+nameOverride: "rancher-monitoring-v2"
 
 ## Override the deployment namespace
+## NOTE: If you change this value, you must update the prometheus-adapter.prometheus.url
 ##
-namespaceOverride: ""
+namespaceOverride: "rancher-monitoring-v2"
 
 ## Provide a k8s version to auto dashboard import script example: kubeTargetVersionOverride: 1.16.6
 ##
@@ -102,7 +124,7 @@
 
   ## Deploy alertmanager
   ##
-  enabled: true
+  enabled: false
 
   ## Api that prometheus will use to communicate with alertmanager. Possible values are v1, v2
   ##
@@ -409,9 +431,13 @@
     ## Define resources requests and limits for single Pods.
     ## ref: https://kubernetes.io/docs/user-guide/compute-resources/
     ##
-    resources: {}
-    # requests:
-    #   memory: 400Mi
+    resources:
+      limits:
+        memory: 500Mi
+        cpu: 1000m
+      requests:
+        memory: 100Mi
+        cpu: 100m
 
     ## Pod anti-affinity can prevent the scheduler from placing Prometheus replicas on the same node.
     ## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
@@ -574,6 +600,19 @@
   ##
   service:
     portName: service
+    ## Port for Grafana Service to listen on
+    ##
+    port: 80
+    ## To be used with a proxy extraContainer port
+    ##
+    targetPort: 3000
+    ## Port to expose on each node
+    ## Only used if service.type is 'NodePort'
+    ##
+    nodePort: 30950
+    ## Service type
+    ##
+    type: NodePort
 
   ## If true, create a serviceMonitor for grafana
   ##
@@ -599,6 +638,14 @@
     #   targetLabel: nodename
     #   replacement: $1
     #   action: replace
+  
+  resources:
+    limits:
+      memory: 200Mi
+      cpu: 200m
+    requests:
+      memory: 100Mi
+      cpu: 100m
 
 ## Component scraping the kube api server
 ##
@@ -755,7 +802,7 @@
 ## Component scraping the kube controller manager
 ##
 kubeControllerManager:
-  enabled: true
+  enabled: false
 
   ## If your kube controller manager is not deployed as a pod, specify IPs it can be found on
   ##
@@ -888,7 +935,7 @@
 ## Component scraping etcd
 ##
 kubeEtcd:
-  enabled: true
+  enabled: false
 
   ## If your etcd is not deployed as a pod, specify IPs it can be found on
   ##
@@ -948,7 +995,7 @@
 ## Component scraping kube scheduler
 ##
 kubeScheduler:
-  enabled: true
+  enabled: false
 
   ## If your kube scheduler is not deployed as a pod, specify IPs it can be found on
   ##
@@ -1001,7 +1048,7 @@
 ## Component scraping kube proxy
 ##
 kubeProxy:
-  enabled: true
+  enabled: false
 
   ## If your kube proxy is not deployed as a pod, specify IPs it can be found on
   ##
@@ -1075,6 +1122,13 @@
     create: true
   podSecurityPolicy:
     enabled: true
+  resources:
+    limits:
+      cpu: 100m
+      memory: 200Mi
+    requests:
+      cpu: 100m
+      memory: 130Mi
 
 ## Deploy node exporter as a daemonset to all nodes
 ##
@@ -1124,6 +1178,16 @@
   extraArgs:
     - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
     - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$
+  service:
+    port: 9796
+    targetPort: 9796
+  resources:
+    limits:
+      cpu: 200m
+      memory: 50Mi
+    requests:
+      cpu: 100m
+      memory: 30Mi
 
 ## Manages Prometheus and Alertmanager components
 ##
@@ -1280,13 +1344,13 @@
 
   ## Resource limits & requests
   ##
-  resources: {}
-  # limits:
-  #   cpu: 200m
-  #   memory: 200Mi
-  # requests:
-  #   cpu: 100m
-  #   memory: 100Mi
+  resources:
+    limits:
+      cpu: 200m
+      memory: 500Mi
+    requests:
+      cpu: 100m
+      memory: 50Mi
 
   # Required for use in managed kubernetes clusters (such as AWS EKS) with custom CNI (such as calico),
   # because control-plane managed by AWS cannot communicate with pods' IP CIDR and admission webhooks are not working
@@ -1408,7 +1472,7 @@
     loadBalancerSourceRanges: []
     ## Service type
     ##
-    type: ClusterIP
+    type: NodePort
 
     sessionAffinity: ""
 
@@ -1628,6 +1692,11 @@
     ##
     externalUrl: ""
 
+    ## Ignore NamespaceSelector settings from the PodMonitor and ServiceMonitor configs
+    ## If true, PodMonitors and ServiceMonitors can only discover Pods and Services within the namespace they are deployed into
+    ##
+    ignoreNamespaceSelectors: true
+
     ## Define which Nodes the Pods are scheduled on.
     ## ref: https://kubernetes.io/docs/user-guide/node-selection/
     ##
@@ -1802,9 +1871,13 @@
 
     ## Resource limits & requests
     ##
-    resources: {}
-    # requests:
-    #   memory: 400Mi
+    resources:
+      limits:
+        memory: 500Mi
+        cpu: 1000m
+      requests:
+        memory: 100Mi
+        cpu: 100m
 
     ## Prometheus StorageSpec for persistent data
     ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/storage.md
